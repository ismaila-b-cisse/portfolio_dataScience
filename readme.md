Ce dépôt présente un portfolio qui a pour objectif de passer en revue les grandes étapes de la science des données, de l'extraction des données jusqu'à la modélisation des données en passant par le nettoyage et la transformation, l'exploration, l'analyse et la visualisation des données. 

Le plan est ainsi constitué : 
1 - Extraction 
2 - Nettoyage et transformation
3 - Exploration (data mining)
4 - Analyse et Visualisation 
5 - Modélisation

Pour l'extraction, j'utiliserai les techniques de scraping pour extraire les données. Les données que j'utilise sont celles des sites e-commerces, notamment darty, temu, amazon, etc. Dans cette partie, nous discuterons également du scraping et l'éthique. 

Pour le nettoyage, je me concentre d'abord au nettoyage des datasets issus des sites e-commerces séparément. Ensuite, j'étudierai la pertinence de faire une jointure entre les les datasets.

Pour l'exploration, j'étudierai les données en profondeur pour mieux les comprendre.

Pourl'analyse et la visualisation, j'étudierai certaines KPI (Key Performances Indicators ou indicateurs de performances).

Pour la modélisation, je pourrai utiliser un dataset différent pour faire prédire une variable selon certaines caractéristiques ou faire du NLP. 